{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"cal_housing_clean.csv\")\n",
    "X=data.drop('medianHouseValue',axis=1)\n",
    "y=data['medianHouseValue']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0                  41.0       880.0          129.0       322.0       126.0   \n",
       "1                  21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2                  52.0      1467.0          190.0       496.0       177.0   \n",
       "3                  52.0      1274.0          235.0       558.0       219.0   \n",
       "4                  52.0      1627.0          280.0       565.0       259.0   \n",
       "5                  52.0       919.0          213.0       413.0       193.0   \n",
       "6                  52.0      2535.0          489.0      1094.0       514.0   \n",
       "7                  52.0      3104.0          687.0      1157.0       647.0   \n",
       "8                  42.0      2555.0          665.0      1206.0       595.0   \n",
       "9                  52.0      3549.0          707.0      1551.0       714.0   \n",
       "10                 52.0      2202.0          434.0       910.0       402.0   \n",
       "11                 52.0      3503.0          752.0      1504.0       734.0   \n",
       "12                 52.0      2491.0          474.0      1098.0       468.0   \n",
       "13                 52.0       696.0          191.0       345.0       174.0   \n",
       "14                 52.0      2643.0          626.0      1212.0       620.0   \n",
       "15                 50.0      1120.0          283.0       697.0       264.0   \n",
       "16                 52.0      1966.0          347.0       793.0       331.0   \n",
       "17                 52.0      1228.0          293.0       648.0       303.0   \n",
       "18                 50.0      2239.0          455.0       990.0       419.0   \n",
       "19                 52.0      1503.0          298.0       690.0       275.0   \n",
       "20                 40.0       751.0          184.0       409.0       166.0   \n",
       "21                 42.0      1639.0          367.0       929.0       366.0   \n",
       "22                 52.0      2436.0          541.0      1015.0       478.0   \n",
       "23                 52.0      1688.0          337.0       853.0       325.0   \n",
       "24                 52.0      2224.0          437.0      1006.0       422.0   \n",
       "25                 41.0       535.0          123.0       317.0       119.0   \n",
       "26                 49.0      1130.0          244.0       607.0       239.0   \n",
       "27                 52.0      1898.0          421.0      1102.0       397.0   \n",
       "28                 50.0      2082.0          492.0      1131.0       473.0   \n",
       "29                 52.0       729.0          160.0       395.0       155.0   \n",
       "...                 ...         ...            ...         ...         ...   \n",
       "20610              28.0      2130.0          484.0      1195.0       439.0   \n",
       "20611              27.0      1783.0          441.0      1163.0       409.0   \n",
       "20612              26.0      1377.0          289.0       761.0       267.0   \n",
       "20613              31.0      1728.0          365.0      1167.0       384.0   \n",
       "20614              26.0      2276.0          460.0      1455.0       474.0   \n",
       "20615              23.0      1076.0          216.0       724.0       197.0   \n",
       "20616              15.0      1810.0          441.0      1157.0       375.0   \n",
       "20617              20.0       561.0          109.0       308.0       114.0   \n",
       "20618              25.0      1332.0          247.0       726.0       226.0   \n",
       "20619              22.0      1891.0          340.0      1023.0       296.0   \n",
       "20620              40.0       198.0           41.0       151.0        48.0   \n",
       "20621              37.0      1244.0          247.0       484.0       157.0   \n",
       "20622              20.0       755.0          147.0       457.0       157.0   \n",
       "20623              32.0      1158.0          244.0       598.0       227.0   \n",
       "20624              16.0      1698.0          300.0       731.0       291.0   \n",
       "20625              37.0       102.0           17.0        29.0        14.0   \n",
       "20626              36.0      1124.0          184.0       504.0       171.0   \n",
       "20627               5.0       358.0           65.0       169.0        59.0   \n",
       "20628              19.0      2043.0          421.0      1018.0       390.0   \n",
       "20629              28.0     10035.0         1856.0      6912.0      1818.0   \n",
       "20630              11.0      2640.0          505.0      1257.0       445.0   \n",
       "20631              15.0      2655.0          493.0      1200.0       432.0   \n",
       "20632              15.0      2319.0          416.0      1047.0       385.0   \n",
       "20633              27.0      2080.0          412.0      1082.0       382.0   \n",
       "20634              28.0      2332.0          395.0      1041.0       344.0   \n",
       "20635              25.0      1665.0          374.0       845.0       330.0   \n",
       "20636              18.0       697.0          150.0       356.0       114.0   \n",
       "20637              17.0      2254.0          485.0      1007.0       433.0   \n",
       "20638              18.0      1860.0          409.0       741.0       349.0   \n",
       "20639              16.0      2785.0          616.0      1387.0       530.0   \n",
       "\n",
       "       medianIncome  medianHouseValue  \n",
       "0            8.3252          452600.0  \n",
       "1            8.3014          358500.0  \n",
       "2            7.2574          352100.0  \n",
       "3            5.6431          341300.0  \n",
       "4            3.8462          342200.0  \n",
       "5            4.0368          269700.0  \n",
       "6            3.6591          299200.0  \n",
       "7            3.1200          241400.0  \n",
       "8            2.0804          226700.0  \n",
       "9            3.6912          261100.0  \n",
       "10           3.2031          281500.0  \n",
       "11           3.2705          241800.0  \n",
       "12           3.0750          213500.0  \n",
       "13           2.6736          191300.0  \n",
       "14           1.9167          159200.0  \n",
       "15           2.1250          140000.0  \n",
       "16           2.7750          152500.0  \n",
       "17           2.1202          155500.0  \n",
       "18           1.9911          158700.0  \n",
       "19           2.6033          162900.0  \n",
       "20           1.3578          147500.0  \n",
       "21           1.7135          159800.0  \n",
       "22           1.7250          113900.0  \n",
       "23           2.1806           99700.0  \n",
       "24           2.6000          132600.0  \n",
       "25           2.4038          107500.0  \n",
       "26           2.4597           93800.0  \n",
       "27           1.8080          105500.0  \n",
       "28           1.6424          108900.0  \n",
       "29           1.6875          132000.0  \n",
       "...             ...               ...  \n",
       "20610        1.3631           45500.0  \n",
       "20611        1.2857           47000.0  \n",
       "20612        1.4934           48300.0  \n",
       "20613        1.4958           53400.0  \n",
       "20614        2.4695           58000.0  \n",
       "20615        2.3598           57500.0  \n",
       "20616        2.0469           55100.0  \n",
       "20617        3.3021           70800.0  \n",
       "20618        2.2500           63400.0  \n",
       "20619        2.7303           99100.0  \n",
       "20620        4.5625          100000.0  \n",
       "20621        2.3661           77500.0  \n",
       "20622        2.4167           67000.0  \n",
       "20623        2.8235           65500.0  \n",
       "20624        3.0739           87200.0  \n",
       "20625        4.1250           72000.0  \n",
       "20626        2.1667           93800.0  \n",
       "20627        3.0000          162500.0  \n",
       "20628        2.5952           92400.0  \n",
       "20629        2.0943          108300.0  \n",
       "20630        3.5673          112000.0  \n",
       "20631        3.5179          107200.0  \n",
       "20632        3.1250          115600.0  \n",
       "20633        2.5495           98300.0  \n",
       "20634        3.7125          116800.0  \n",
       "20635        1.5603           78100.0  \n",
       "20636        2.5568           77100.0  \n",
       "20637        1.7000           92300.0  \n",
       "20638        1.8672           84700.0  \n",
       "20639        2.3886           89400.0  \n",
       "\n",
       "[20640 rows x 7 columns]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaled_X_train=pd.DataFrame(data=scaler.fit_transform(X_train),columns=X_train.columns,index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaled_X_test=pd.DataFrame(data=scaler.fit_transform(X_test),columns=X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.101730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>0.050745</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.121412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.072215</td>\n",
       "      <td>0.061297</td>\n",
       "      <td>0.038790</td>\n",
       "      <td>0.059694</td>\n",
       "      <td>0.399932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.185444</td>\n",
       "      <td>0.085428</td>\n",
       "      <td>0.164282</td>\n",
       "      <td>0.084137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.118667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.322851</td>\n",
       "      <td>0.251241</td>\n",
       "      <td>0.123490</td>\n",
       "      <td>0.266568</td>\n",
       "      <td>0.425518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.036904</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.575654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.328182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10458</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.028449</td>\n",
       "      <td>0.865526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.467648</td>\n",
       "      <td>0.352886</td>\n",
       "      <td>0.203565</td>\n",
       "      <td>0.384312</td>\n",
       "      <td>0.383905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17617</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133456</td>\n",
       "      <td>0.206859</td>\n",
       "      <td>0.055074</td>\n",
       "      <td>0.204572</td>\n",
       "      <td>0.215825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17838</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.067259</td>\n",
       "      <td>0.316009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.102989</td>\n",
       "      <td>0.123836</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.123828</td>\n",
       "      <td>0.207514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12022</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.242789</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>0.136159</td>\n",
       "      <td>0.227594</td>\n",
       "      <td>0.261969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12897</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.067464</td>\n",
       "      <td>0.076350</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>0.080743</td>\n",
       "      <td>0.133398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.083023</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>0.044729</td>\n",
       "      <td>0.104205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14849</th>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>0.114215</td>\n",
       "      <td>0.065529</td>\n",
       "      <td>0.115770</td>\n",
       "      <td>0.104240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>0.029934</td>\n",
       "      <td>0.094228</td>\n",
       "      <td>0.051951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.095571</td>\n",
       "      <td>0.099317</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.086334</td>\n",
       "      <td>0.106709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12615</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.144582</td>\n",
       "      <td>0.115456</td>\n",
       "      <td>0.051963</td>\n",
       "      <td>0.121362</td>\n",
       "      <td>0.312906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.092681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.014276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12812</th>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.249716</td>\n",
       "      <td>0.296710</td>\n",
       "      <td>0.082121</td>\n",
       "      <td>0.265581</td>\n",
       "      <td>0.219231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.124146</td>\n",
       "      <td>0.081168</td>\n",
       "      <td>0.130077</td>\n",
       "      <td>0.141529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.298279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.028506</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>0.039796</td>\n",
       "      <td>0.062337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.026207</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.026094</td>\n",
       "      <td>0.037165</td>\n",
       "      <td>0.147170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20516</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>0.072936</td>\n",
       "      <td>0.029093</td>\n",
       "      <td>0.074165</td>\n",
       "      <td>0.164832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.054542</td>\n",
       "      <td>0.108206</td>\n",
       "      <td>0.290230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.250003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.040858</td>\n",
       "      <td>0.048262</td>\n",
       "      <td>0.032989</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.099799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.012498</td>\n",
       "      <td>0.234486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.066759</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.036507</td>\n",
       "      <td>0.143970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18430</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.072981</td>\n",
       "      <td>0.053073</td>\n",
       "      <td>0.032036</td>\n",
       "      <td>0.055912</td>\n",
       "      <td>0.353264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.082391</td>\n",
       "      <td>0.102110</td>\n",
       "      <td>0.048880</td>\n",
       "      <td>0.101299</td>\n",
       "      <td>0.198025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.031811</td>\n",
       "      <td>0.058543</td>\n",
       "      <td>0.152591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056245</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>0.029681</td>\n",
       "      <td>0.056241</td>\n",
       "      <td>0.103454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.042365</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.048512</td>\n",
       "      <td>0.176335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.184735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>0.160615</td>\n",
       "      <td>0.083298</td>\n",
       "      <td>0.167242</td>\n",
       "      <td>0.395305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.086345</td>\n",
       "      <td>0.094351</td>\n",
       "      <td>0.048067</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.210673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16921</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.094498</td>\n",
       "      <td>0.135785</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>0.202301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.047896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18606</th>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.087418</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.037417</td>\n",
       "      <td>0.085019</td>\n",
       "      <td>0.237404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.165916</td>\n",
       "      <td>0.128181</td>\n",
       "      <td>0.057681</td>\n",
       "      <td>0.117250</td>\n",
       "      <td>0.473662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18983</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.126774</td>\n",
       "      <td>0.117474</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.118730</td>\n",
       "      <td>0.186066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17089</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.137936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.059770</td>\n",
       "      <td>0.072936</td>\n",
       "      <td>0.026150</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.162908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.063935</td>\n",
       "      <td>0.040864</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.104943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6744</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>0.044382</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.257327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15832</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069977</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>0.296182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15430</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.049931</td>\n",
       "      <td>0.064246</td>\n",
       "      <td>0.029205</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>0.134522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.094897</td>\n",
       "      <td>0.075885</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>0.079428</td>\n",
       "      <td>0.308913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14116</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>0.109094</td>\n",
       "      <td>0.056111</td>\n",
       "      <td>0.109686</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.027556</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>0.119833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.040215</td>\n",
       "      <td>0.035382</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.269831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.034207</td>\n",
       "      <td>0.030106</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>0.034205</td>\n",
       "      <td>0.166453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.043801</td>\n",
       "      <td>0.057263</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.064463</td>\n",
       "      <td>0.186053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>0.077126</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.076797</td>\n",
       "      <td>0.353899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.050745</td>\n",
       "      <td>0.028616</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.061261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14448 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "1989           1.000000    0.003372       0.004190    0.005325    0.006413   \n",
       "256            0.823529    0.031111       0.050745    0.023347    0.045387   \n",
       "7887           0.313725    0.072215       0.061297    0.038790    0.059694   \n",
       "4581           0.313725    0.077119       0.185444    0.085428    0.164282   \n",
       "1993           0.960784    0.023602       0.029950    0.016901    0.027298   \n",
       "10326          0.196078    0.322851       0.251241    0.123490    0.266568   \n",
       "10339          0.254902    0.036904       0.021881    0.015948    0.024338   \n",
       "12992          0.313725    0.120000       0.098852    0.050618    0.092583   \n",
       "10458          0.098039    0.050146       0.029019    0.015948    0.028449   \n",
       "1700           0.176471    0.467648       0.352886    0.203565    0.384312   \n",
       "17617          0.333333    0.133456       0.206859    0.055074    0.204572   \n",
       "17838          0.058824    0.050391       0.063160    0.023824    0.067259   \n",
       "6859           0.588235    0.102989       0.123836    0.054262    0.123828   \n",
       "12022          0.215686    0.242789       0.227964    0.136159    0.227594   \n",
       "12897          0.509804    0.067464       0.076350    0.032372    0.080743   \n",
       "2767           0.274510    0.059556       0.083023    0.014350    0.044729   \n",
       "14849          0.372549    0.078682       0.114215    0.065529    0.115770   \n",
       "9073           0.215686    0.060751       0.095127    0.029934    0.094228   \n",
       "1217           0.294118    0.095571       0.099317    0.036884    0.086334   \n",
       "12615          0.470588    0.144582       0.115456    0.051963    0.121362   \n",
       "13498          0.607843    0.051770       0.054624    0.040752    0.053938   \n",
       "13510          0.549020    0.010084       0.013035    0.009473    0.017431   \n",
       "12812          0.078431    0.249716       0.296710    0.082121    0.265581   \n",
       "4392           0.725490    0.069364       0.124146    0.081168    0.130077   \n",
       "1948           0.196078    0.030989       0.029019    0.011407    0.025818   \n",
       "2502           0.215686    0.028506       0.037709    0.029149    0.039796   \n",
       "7475           0.784314    0.026207       0.031037    0.026094    0.037165   \n",
       "20516          0.823529    0.072276       0.072936    0.029093    0.074165   \n",
       "1927           0.274510    0.159877       0.110180    0.054542    0.108206   \n",
       "12068          0.098039    0.006130       0.004345    0.002018    0.004440   \n",
       "...                 ...         ...            ...         ...         ...   \n",
       "2496           0.450980    0.040858       0.048262    0.032989    0.043743   \n",
       "7599           0.686275    0.012383       0.010863    0.007427    0.012498   \n",
       "1871           0.450980    0.066759       0.080074    0.021077    0.036507   \n",
       "18430          0.450980    0.072981       0.053073    0.032036    0.055912   \n",
       "7877           0.549020    0.082391       0.102110    0.048880    0.101299   \n",
       "4851           0.764706    0.051893       0.057883    0.031811    0.058543   \n",
       "5072           1.000000    0.056245       0.065953    0.029681    0.056241   \n",
       "2163           0.784314    0.044107       0.042365    0.018022    0.048512   \n",
       "6036           0.647059    0.010483       0.016605    0.008745    0.019405   \n",
       "6921           0.176471    0.200123       0.160615    0.083298    0.167242   \n",
       "6216           0.647059    0.086345       0.094351    0.048067    0.091597   \n",
       "16921          0.509804    0.094498       0.135785    0.040640    0.147180   \n",
       "2897           0.843137    0.013241       0.016915    0.007596    0.013978   \n",
       "18606          0.745098    0.087418       0.094972    0.037417    0.085019   \n",
       "10327          0.235294    0.165916       0.128181    0.057681    0.117250   \n",
       "18983          0.294118    0.126774       0.117474    0.049301    0.118730   \n",
       "17089          0.666667    0.011188       0.017381    0.011071    0.017760   \n",
       "14650          0.588235    0.059770       0.072936    0.026150    0.075810   \n",
       "19852          0.333333    0.066084       0.063935    0.040864    0.064792   \n",
       "6744           0.823529    0.047571       0.044382    0.022394    0.045387   \n",
       "15832          1.000000    0.069977       0.078833    0.023431    0.074823   \n",
       "15430          0.470588    0.049931       0.064246    0.029205    0.063312   \n",
       "14935          0.196078    0.094897       0.075885    0.038902    0.079428   \n",
       "14116          0.450980    0.089655       0.109094    0.056111    0.109686   \n",
       "9225           0.352941    0.027556       0.028243    0.019535    0.031080   \n",
       "13123          0.372549    0.040215       0.035382    0.019872    0.035849   \n",
       "19648          0.509804    0.034207       0.030106    0.018050    0.034205   \n",
       "9845           0.588235    0.043801       0.057263    0.019647    0.064463   \n",
       "10799          0.647059    0.065073       0.077126    0.029401    0.076797   \n",
       "2732           0.274510    0.035831       0.050745    0.028616    0.048841   \n",
       "\n",
       "       medianIncome  \n",
       "1989       0.101730  \n",
       "256        0.121412  \n",
       "7887       0.399932  \n",
       "4581       0.084137  \n",
       "1993       0.118667  \n",
       "10326      0.425518  \n",
       "10339      0.575654  \n",
       "12992      0.328182  \n",
       "10458      0.865526  \n",
       "1700       0.383905  \n",
       "17617      0.215825  \n",
       "17838      0.316009  \n",
       "6859       0.207514  \n",
       "12022      0.261969  \n",
       "12897      0.133398  \n",
       "2767       0.104205  \n",
       "14849      0.104240  \n",
       "9073       0.051951  \n",
       "1217       0.106709  \n",
       "12615      0.312906  \n",
       "13498      0.092681  \n",
       "13510      0.014276  \n",
       "12812      0.219231  \n",
       "4392       0.141529  \n",
       "1948       0.298279  \n",
       "2502       0.062337  \n",
       "7475       0.147170  \n",
       "20516      0.164832  \n",
       "1927       0.290230  \n",
       "12068      0.250003  \n",
       "...             ...  \n",
       "2496       0.099799  \n",
       "7599       0.234486  \n",
       "1871       0.143970  \n",
       "18430      0.353264  \n",
       "7877       0.198025  \n",
       "4851       0.152591  \n",
       "5072       0.103454  \n",
       "2163       0.176335  \n",
       "6036       0.184735  \n",
       "6921       0.395305  \n",
       "6216       0.210673  \n",
       "16921      0.202301  \n",
       "2897       0.047896  \n",
       "18606      0.237404  \n",
       "10327      0.473662  \n",
       "18983      0.186066  \n",
       "17089      0.137936  \n",
       "14650      0.162908  \n",
       "19852      0.104943  \n",
       "6744       0.257327  \n",
       "15832      0.296182  \n",
       "15430      0.134522  \n",
       "14935      0.308913  \n",
       "14116      0.119833  \n",
       "9225       0.119833  \n",
       "13123      0.269831  \n",
       "19648      0.166453  \n",
       "9845       0.186053  \n",
       "10799      0.353899  \n",
       "2732       0.061261  \n",
       "\n",
       "[14448 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housingMedianAge=tf.feature_column.numeric_column('housingMedianAge')\n",
    "totalRooms=tf.feature_column.numeric_column('totalRooms')\n",
    "totalBedrooms=tf.feature_column.numeric_column('totalBedrooms')\n",
    "population=tf.feature_column.numeric_column('population')\n",
    "households=tf.feature_column.numeric_column('households')\n",
    "medianIncome=tf.feature_column.numeric_column('medianIncome')\n",
    "features=[housingMedianAge, totalRooms, totalBedrooms, population,\n",
    "       households, medianIncome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmplpxm6bm8\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Gnana\\\\AppData\\\\Local\\\\Temp\\\\tmplpxm6bm8', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "estimator=tf.estimator.LinearRegressor(feature_columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func=tf.estimator.inputs.pandas_input_fn(x=Scaled_X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmplpxm6bm8\\model.ckpt.\n",
      "INFO:tensorflow:loss = 5.02153e+11, step = 1\n",
      "INFO:tensorflow:global_step/sec: 135.503\n",
      "INFO:tensorflow:loss = 6.66497e+11, step = 101 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.923\n",
      "INFO:tensorflow:loss = 6.11128e+11, step = 201 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.174\n",
      "INFO:tensorflow:loss = 4.59357e+11, step = 301 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.33\n",
      "INFO:tensorflow:loss = 9.33221e+11, step = 401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.711\n",
      "INFO:tensorflow:loss = 6.33821e+11, step = 501 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.498\n",
      "INFO:tensorflow:loss = 4.83642e+11, step = 601 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.552\n",
      "INFO:tensorflow:loss = 6.51216e+11, step = 701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.536\n",
      "INFO:tensorflow:loss = 3.44582e+11, step = 801 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.713\n",
      "INFO:tensorflow:loss = 4.13076e+11, step = 901 (0.567 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmplpxm6bm8\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.56677e+11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x236a78af908>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmptjt8qt6b\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Gnana\\\\AppData\\\\Local\\\\Temp\\\\tmptjt8qt6b', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6,6],feature_columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmptjt8qt6b\\model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmptjt8qt6b\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.38453e+11, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 191.505\n",
      "INFO:tensorflow:loss = 1.1246e+11, step = 1101 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.463\n",
      "INFO:tensorflow:loss = 8.76399e+10, step = 1201 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.342\n",
      "INFO:tensorflow:loss = 1.34304e+11, step = 1301 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.525\n",
      "INFO:tensorflow:loss = 7.89185e+10, step = 1401 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.379\n",
      "INFO:tensorflow:loss = 7.85571e+10, step = 1501 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.55\n",
      "INFO:tensorflow:loss = 3.46566e+10, step = 1601 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.865\n",
      "INFO:tensorflow:loss = 1.84422e+11, step = 1701 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.511\n",
      "INFO:tensorflow:loss = 7.78905e+10, step = 1801 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.698\n",
      "INFO:tensorflow:loss = 1.4217e+11, step = 1901 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.425\n",
      "INFO:tensorflow:loss = 9.32163e+10, step = 2001 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.983\n",
      "INFO:tensorflow:loss = 6.70724e+10, step = 2101 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.938\n",
      "INFO:tensorflow:loss = 7.67253e+10, step = 2201 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.756\n",
      "INFO:tensorflow:loss = 8.95436e+10, step = 2301 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.642\n",
      "INFO:tensorflow:loss = 7.37661e+10, step = 2401 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.654\n",
      "INFO:tensorflow:loss = 1.55043e+11, step = 2501 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.336\n",
      "INFO:tensorflow:loss = 1.58127e+11, step = 2601 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.733\n",
      "INFO:tensorflow:loss = 3.39203e+10, step = 2701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.862\n",
      "INFO:tensorflow:loss = 7.09841e+10, step = 2801 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.854\n",
      "INFO:tensorflow:loss = 8.94873e+10, step = 2901 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.819\n",
      "INFO:tensorflow:loss = 6.51875e+10, step = 3001 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.477\n",
      "INFO:tensorflow:loss = 8.69881e+10, step = 3101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.74\n",
      "INFO:tensorflow:loss = 7.62794e+10, step = 3201 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.561\n",
      "INFO:tensorflow:loss = 1.11467e+11, step = 3301 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.816\n",
      "INFO:tensorflow:loss = 7.22733e+10, step = 3401 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.784\n",
      "INFO:tensorflow:loss = 9.51175e+10, step = 3501 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.672\n",
      "INFO:tensorflow:loss = 5.41888e+10, step = 3601 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.6\n",
      "INFO:tensorflow:loss = 6.59208e+10, step = 3701 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.629\n",
      "INFO:tensorflow:loss = 5.75022e+10, step = 3801 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.876\n",
      "INFO:tensorflow:loss = 2.56211e+10, step = 3901 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.997\n",
      "INFO:tensorflow:loss = 8.65055e+10, step = 4001 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.567\n",
      "INFO:tensorflow:loss = 6.93871e+10, step = 4101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.403\n",
      "INFO:tensorflow:loss = 1.50834e+11, step = 4201 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.89\n",
      "INFO:tensorflow:loss = 9.78999e+10, step = 4301 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.108\n",
      "INFO:tensorflow:loss = 6.9311e+10, step = 4401 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.894\n",
      "INFO:tensorflow:loss = 1.13095e+11, step = 4501 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.581\n",
      "INFO:tensorflow:loss = 8.0794e+10, step = 4601 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.336\n",
      "INFO:tensorflow:loss = 9.58256e+10, step = 4701 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.776\n",
      "INFO:tensorflow:loss = 1.1819e+11, step = 4801 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.817\n",
      "INFO:tensorflow:loss = 1.47833e+11, step = 4901 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.554\n",
      "INFO:tensorflow:loss = 1.75662e+11, step = 5001 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.588\n",
      "INFO:tensorflow:loss = 5.7967e+10, step = 5101 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.647\n",
      "INFO:tensorflow:loss = 7.13122e+10, step = 5201 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.693\n",
      "INFO:tensorflow:loss = 9.9269e+10, step = 5301 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.057\n",
      "INFO:tensorflow:loss = 8.28722e+10, step = 5401 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.747\n",
      "INFO:tensorflow:loss = 6.4075e+10, step = 5501 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.822\n",
      "INFO:tensorflow:loss = 7.35683e+10, step = 5601 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.307\n",
      "INFO:tensorflow:loss = 6.08735e+10, step = 5701 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.209\n",
      "INFO:tensorflow:loss = 8.1596e+10, step = 5801 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.732\n",
      "INFO:tensorflow:loss = 2.30124e+11, step = 5901 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.137\n",
      "INFO:tensorflow:loss = 1.32419e+11, step = 6001 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.889\n",
      "INFO:tensorflow:loss = 4.69474e+10, step = 6101 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.279\n",
      "INFO:tensorflow:loss = 5.18429e+10, step = 6201 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.628\n",
      "INFO:tensorflow:loss = 1.07131e+11, step = 6301 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.402\n",
      "INFO:tensorflow:loss = 5.98923e+10, step = 6401 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.515\n",
      "INFO:tensorflow:loss = 9.92523e+10, step = 6501 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.176\n",
      "INFO:tensorflow:loss = 8.26772e+10, step = 6601 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.819\n",
      "INFO:tensorflow:loss = 4.96103e+10, step = 6701 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.385\n",
      "INFO:tensorflow:loss = 5.873e+10, step = 6801 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.884\n",
      "INFO:tensorflow:loss = 8.08572e+10, step = 6901 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.685\n",
      "INFO:tensorflow:loss = 5.83457e+10, step = 7001 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.036\n",
      "INFO:tensorflow:loss = 1.7243e+11, step = 7101 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.959\n",
      "INFO:tensorflow:loss = 8.00195e+10, step = 7201 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.049\n",
      "INFO:tensorflow:loss = 2.85645e+10, step = 7301 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.637\n",
      "INFO:tensorflow:loss = 1.02471e+11, step = 7401 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.92\n",
      "INFO:tensorflow:loss = 2.96333e+10, step = 7501 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.055\n",
      "INFO:tensorflow:loss = 2.36441e+10, step = 7601 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.599\n",
      "INFO:tensorflow:loss = 5.13417e+10, step = 7701 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.421\n",
      "INFO:tensorflow:loss = 4.60629e+10, step = 7801 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.628\n",
      "INFO:tensorflow:loss = 6.38486e+10, step = 7901 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.96\n",
      "INFO:tensorflow:loss = 3.1657e+10, step = 8001 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.863\n",
      "INFO:tensorflow:loss = 9.1915e+10, step = 8101 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.359\n",
      "INFO:tensorflow:loss = 8.37867e+10, step = 8201 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.919\n",
      "INFO:tensorflow:loss = 1.17166e+11, step = 8301 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.228\n",
      "INFO:tensorflow:loss = 6.78185e+10, step = 8401 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.653\n",
      "INFO:tensorflow:loss = 9.01529e+10, step = 8501 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.188\n",
      "INFO:tensorflow:loss = 4.11865e+10, step = 8601 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.871\n",
      "INFO:tensorflow:loss = 7.98829e+10, step = 8701 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.105\n",
      "INFO:tensorflow:loss = 9.26093e+10, step = 8801 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.75232e+11, step = 8901 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.693\n",
      "INFO:tensorflow:loss = 1.54721e+11, step = 9001 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.659\n",
      "INFO:tensorflow:loss = 1.47884e+11, step = 9101 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.991\n",
      "INFO:tensorflow:loss = 4.3857e+10, step = 9201 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.653\n",
      "INFO:tensorflow:loss = 9.2546e+10, step = 9301 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.662\n",
      "INFO:tensorflow:loss = 4.93933e+10, step = 9401 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.797\n",
      "INFO:tensorflow:loss = 1.43607e+11, step = 9501 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.809\n",
      "INFO:tensorflow:loss = 6.70469e+10, step = 9601 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.029\n",
      "INFO:tensorflow:loss = 3.58122e+10, step = 9701 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.567\n",
      "INFO:tensorflow:loss = 4.79422e+10, step = 9801 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.542\n",
      "INFO:tensorflow:loss = 4.58616e+10, step = 9901 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.677\n",
      "INFO:tensorflow:loss = 1.04005e+11, step = 10001 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.002\n",
      "INFO:tensorflow:loss = 7.5818e+10, step = 10101 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.994\n",
      "INFO:tensorflow:loss = 8.72703e+10, step = 10201 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.371\n",
      "INFO:tensorflow:loss = 2.57806e+10, step = 10301 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.547\n",
      "INFO:tensorflow:loss = 5.01944e+10, step = 10401 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.197\n",
      "INFO:tensorflow:loss = 8.70224e+10, step = 10501 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.44\n",
      "INFO:tensorflow:loss = 1.14233e+11, step = 10601 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.749\n",
      "INFO:tensorflow:loss = 1.64197e+11, step = 10701 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.764\n",
      "INFO:tensorflow:loss = 2.96636e+10, step = 10801 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.606\n",
      "INFO:tensorflow:loss = 7.08631e+10, step = 10901 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.802\n",
      "INFO:tensorflow:loss = 1.28374e+11, step = 11001 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.094\n",
      "INFO:tensorflow:loss = 5.12875e+10, step = 11101 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.673\n",
      "INFO:tensorflow:loss = 5.99809e+10, step = 11201 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.353\n",
      "INFO:tensorflow:loss = 2.098e+10, step = 11301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.089\n",
      "INFO:tensorflow:loss = 8.13426e+10, step = 11401 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.362\n",
      "INFO:tensorflow:loss = 4.59895e+10, step = 11501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.647\n",
      "INFO:tensorflow:loss = 9.6827e+10, step = 11601 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.602\n",
      "INFO:tensorflow:loss = 4.03647e+10, step = 11701 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.656\n",
      "INFO:tensorflow:loss = 4.50302e+10, step = 11801 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.771\n",
      "INFO:tensorflow:loss = 7.25267e+10, step = 11901 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.03\n",
      "INFO:tensorflow:loss = 7.05665e+10, step = 12001 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.859\n",
      "INFO:tensorflow:loss = 7.95067e+10, step = 12101 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.225\n",
      "INFO:tensorflow:loss = 3.60735e+10, step = 12201 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.515\n",
      "INFO:tensorflow:loss = 1.77454e+10, step = 12301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.079\n",
      "INFO:tensorflow:loss = 5.69922e+10, step = 12401 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.641\n",
      "INFO:tensorflow:loss = 3.67098e+10, step = 12501 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.656\n",
      "INFO:tensorflow:loss = 9.28857e+10, step = 12601 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.312\n",
      "INFO:tensorflow:loss = 6.22927e+10, step = 12701 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.992\n",
      "INFO:tensorflow:loss = 3.41705e+10, step = 12801 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.567\n",
      "INFO:tensorflow:loss = 3.1305e+10, step = 12901 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.816\n",
      "INFO:tensorflow:loss = 8.89166e+10, step = 13001 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.753\n",
      "INFO:tensorflow:loss = 5.08124e+10, step = 13101 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.661\n",
      "INFO:tensorflow:loss = 7.2811e+10, step = 13201 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.533\n",
      "INFO:tensorflow:loss = 4.24428e+10, step = 13301 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.952\n",
      "INFO:tensorflow:loss = 6.07916e+10, step = 13401 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.381\n",
      "INFO:tensorflow:loss = 1.10826e+11, step = 13501 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.27\n",
      "INFO:tensorflow:loss = 1.42634e+11, step = 13601 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.536\n",
      "INFO:tensorflow:loss = 3.44465e+10, step = 13701 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.317\n",
      "INFO:tensorflow:loss = 1.36548e+11, step = 13801 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.602\n",
      "INFO:tensorflow:loss = 1.11324e+11, step = 13901 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.666\n",
      "INFO:tensorflow:loss = 8.61717e+10, step = 14001 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.13\n",
      "INFO:tensorflow:loss = 6.06643e+10, step = 14101 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.655\n",
      "INFO:tensorflow:loss = 5.04582e+10, step = 14201 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.05\n",
      "INFO:tensorflow:loss = 5.54929e+10, step = 14301 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.723\n",
      "INFO:tensorflow:loss = 9.72353e+10, step = 14401 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.674\n",
      "INFO:tensorflow:loss = 4.57984e+10, step = 14501 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.519\n",
      "INFO:tensorflow:loss = 5.26179e+10, step = 14601 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.717\n",
      "INFO:tensorflow:loss = 6.15579e+10, step = 14701 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.599\n",
      "INFO:tensorflow:loss = 3.13723e+10, step = 14801 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.89\n",
      "INFO:tensorflow:loss = 9.95433e+10, step = 14901 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.596\n",
      "INFO:tensorflow:loss = 3.76326e+10, step = 15001 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.91\n",
      "INFO:tensorflow:loss = 6.2296e+10, step = 15101 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.865\n",
      "INFO:tensorflow:loss = 6.01699e+10, step = 15201 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.576\n",
      "INFO:tensorflow:loss = 2.24098e+10, step = 15301 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.653\n",
      "INFO:tensorflow:loss = 5.0698e+10, step = 15401 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.561\n",
      "INFO:tensorflow:loss = 1.17527e+11, step = 15501 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.111\n",
      "INFO:tensorflow:loss = 5.36929e+10, step = 15601 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.825\n",
      "INFO:tensorflow:loss = 2.99214e+10, step = 15701 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.35\n",
      "INFO:tensorflow:loss = 1.19435e+11, step = 15801 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.852\n",
      "INFO:tensorflow:loss = 5.08222e+10, step = 15901 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.031\n",
      "INFO:tensorflow:loss = 3.52179e+10, step = 16001 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.785\n",
      "INFO:tensorflow:loss = 5.11116e+10, step = 16101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.677\n",
      "INFO:tensorflow:loss = 1.00557e+11, step = 16201 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.634\n",
      "INFO:tensorflow:loss = 1.75661e+10, step = 16301 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.59\n",
      "INFO:tensorflow:loss = 4.87161e+10, step = 16401 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.755\n",
      "INFO:tensorflow:loss = 5.2394e+10, step = 16501 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.832\n",
      "INFO:tensorflow:loss = 4.72917e+10, step = 16601 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.009\n",
      "INFO:tensorflow:loss = 5.18687e+10, step = 16701 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.607\n",
      "INFO:tensorflow:loss = 5.43186e+10, step = 16801 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.796\n",
      "INFO:tensorflow:loss = 1.343e+11, step = 16901 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.19429e+10, step = 17001 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.66\n",
      "INFO:tensorflow:loss = 7.07934e+10, step = 17101 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.308\n",
      "INFO:tensorflow:loss = 8.2886e+10, step = 17201 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.532\n",
      "INFO:tensorflow:loss = 7.2759e+10, step = 17301 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.683\n",
      "INFO:tensorflow:loss = 3.84644e+10, step = 17401 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.031\n",
      "INFO:tensorflow:loss = 3.87826e+10, step = 17501 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.529\n",
      "INFO:tensorflow:loss = 1.28176e+11, step = 17601 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.105\n",
      "INFO:tensorflow:loss = 4.51021e+10, step = 17701 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.387\n",
      "INFO:tensorflow:loss = 7.46887e+10, step = 17801 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.74\n",
      "INFO:tensorflow:loss = 5.75771e+10, step = 17901 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.708\n",
      "INFO:tensorflow:loss = 3.3702e+10, step = 18001 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.111\n",
      "INFO:tensorflow:loss = 7.8662e+10, step = 18101 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.079\n",
      "INFO:tensorflow:loss = 1.56957e+11, step = 18201 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.37\n",
      "INFO:tensorflow:loss = 5.50011e+10, step = 18301 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.504\n",
      "INFO:tensorflow:loss = 1.07169e+11, step = 18401 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.307\n",
      "INFO:tensorflow:loss = 9.00974e+10, step = 18501 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.721\n",
      "INFO:tensorflow:loss = 5.41145e+10, step = 18601 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.42\n",
      "INFO:tensorflow:loss = 1.62178e+11, step = 18701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.022\n",
      "INFO:tensorflow:loss = 4.42704e+10, step = 18801 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.948\n",
      "INFO:tensorflow:loss = 3.46438e+10, step = 18901 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.926\n",
      "INFO:tensorflow:loss = 2.71203e+10, step = 19001 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.544\n",
      "INFO:tensorflow:loss = 2.76917e+10, step = 19101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.773\n",
      "INFO:tensorflow:loss = 8.09646e+10, step = 19201 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.563\n",
      "INFO:tensorflow:loss = 1.30975e+11, step = 19301 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.709\n",
      "INFO:tensorflow:loss = 2.08164e+10, step = 19401 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.525\n",
      "INFO:tensorflow:loss = 5.543e+10, step = 19501 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.572\n",
      "INFO:tensorflow:loss = 5.72791e+10, step = 19601 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.625\n",
      "INFO:tensorflow:loss = 1.62297e+11, step = 19701 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.845\n",
      "INFO:tensorflow:loss = 4.19573e+10, step = 19801 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.063\n",
      "INFO:tensorflow:loss = 1.89571e+10, step = 19901 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.437\n",
      "INFO:tensorflow:loss = 3.59649e+10, step = 20001 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.332\n",
      "INFO:tensorflow:loss = 1.20169e+11, step = 20101 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.008\n",
      "INFO:tensorflow:loss = 7.64715e+10, step = 20201 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.468\n",
      "INFO:tensorflow:loss = 3.90076e+10, step = 20301 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.658\n",
      "INFO:tensorflow:loss = 2.47812e+10, step = 20401 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.09\n",
      "INFO:tensorflow:loss = 8.7677e+10, step = 20501 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.584\n",
      "INFO:tensorflow:loss = 5.92589e+10, step = 20601 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.697\n",
      "INFO:tensorflow:loss = 6.08084e+10, step = 20701 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.631\n",
      "INFO:tensorflow:loss = 5.7136e+10, step = 20801 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.867\n",
      "INFO:tensorflow:loss = 2.22679e+10, step = 20901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.065\n",
      "INFO:tensorflow:loss = 8.2588e+10, step = 21001 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.651\n",
      "INFO:tensorflow:loss = 7.13358e+10, step = 21101 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.303\n",
      "INFO:tensorflow:loss = 7.29769e+10, step = 21201 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.786\n",
      "INFO:tensorflow:loss = 2.17786e+10, step = 21301 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.779\n",
      "INFO:tensorflow:loss = 2.1485e+10, step = 21401 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.222\n",
      "INFO:tensorflow:loss = 1.16103e+11, step = 21501 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.822\n",
      "INFO:tensorflow:loss = 3.04968e+10, step = 21601 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.303\n",
      "INFO:tensorflow:loss = 1.71402e+11, step = 21701 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.625\n",
      "INFO:tensorflow:loss = 1.12801e+10, step = 21801 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.079\n",
      "INFO:tensorflow:loss = 1.34186e+11, step = 21901 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.809\n",
      "INFO:tensorflow:loss = 2.62535e+10, step = 22001 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.673\n",
      "INFO:tensorflow:loss = 2.51867e+10, step = 22101 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.462\n",
      "INFO:tensorflow:loss = 3.06524e+10, step = 22201 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.639\n",
      "INFO:tensorflow:loss = 5.2983e+10, step = 22301 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.627\n",
      "INFO:tensorflow:loss = 3.5683e+10, step = 22401 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.561\n",
      "INFO:tensorflow:loss = 6.43593e+10, step = 22501 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.399\n",
      "INFO:tensorflow:loss = 7.39765e+10, step = 22601 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.679\n",
      "INFO:tensorflow:loss = 8.87399e+10, step = 22701 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.479\n",
      "INFO:tensorflow:loss = 4.56745e+10, step = 22801 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.535\n",
      "INFO:tensorflow:loss = 4.14314e+10, step = 22901 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.395\n",
      "INFO:tensorflow:loss = 4.73463e+10, step = 23001 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.186\n",
      "INFO:tensorflow:loss = 4.09572e+10, step = 23101 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.566\n",
      "INFO:tensorflow:loss = 1.4782e+11, step = 23201 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.707\n",
      "INFO:tensorflow:loss = 3.34794e+10, step = 23301 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.786\n",
      "INFO:tensorflow:loss = 2.67976e+10, step = 23401 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.668\n",
      "INFO:tensorflow:loss = 4.73487e+10, step = 23501 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.942\n",
      "INFO:tensorflow:loss = 8.32392e+10, step = 23601 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.789\n",
      "INFO:tensorflow:loss = 4.68773e+10, step = 23701 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.538\n",
      "INFO:tensorflow:loss = 2.85388e+10, step = 23801 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.799\n",
      "INFO:tensorflow:loss = 4.64398e+10, step = 23901 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.552\n",
      "INFO:tensorflow:loss = 2.34901e+10, step = 24001 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.3\n",
      "INFO:tensorflow:loss = 3.10195e+10, step = 24101 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.936\n",
      "INFO:tensorflow:loss = 9.02028e+10, step = 24201 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.611\n",
      "INFO:tensorflow:loss = 1.43364e+11, step = 24301 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.766\n",
      "INFO:tensorflow:loss = 2.47916e+10, step = 24401 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.592\n",
      "INFO:tensorflow:loss = 7.05491e+10, step = 24501 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.464\n",
      "INFO:tensorflow:loss = 3.42336e+10, step = 24601 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.673\n",
      "INFO:tensorflow:loss = 1.30501e+11, step = 24701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.824\n",
      "INFO:tensorflow:loss = 4.41511e+10, step = 24801 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.963\n",
      "INFO:tensorflow:loss = 8.66412e+10, step = 24901 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.665\n",
      "INFO:tensorflow:loss = 9.09852e+10, step = 25001 (0.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 199.424\n",
      "INFO:tensorflow:loss = 3.66015e+10, step = 25101 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.774\n",
      "INFO:tensorflow:loss = 9.12872e+10, step = 25201 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.391\n",
      "INFO:tensorflow:loss = 3.39123e+10, step = 25301 (0.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.47\n",
      "INFO:tensorflow:loss = 1.85083e+11, step = 25401 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.642\n",
      "INFO:tensorflow:loss = 3.00985e+10, step = 25501 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.156\n",
      "INFO:tensorflow:loss = 1.64273e+10, step = 25601 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.157\n",
      "INFO:tensorflow:loss = 3.62772e+10, step = 25701 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.913\n",
      "INFO:tensorflow:loss = 6.90756e+10, step = 25801 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.947\n",
      "INFO:tensorflow:loss = 3.08322e+10, step = 25901 (0.516 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmptjt8qt6b\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.43995e+10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x236a5a28b38>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_func=tf.estimator.inputs.pandas_input_fn(x=Scaled_X_test,batch_size=10,num_epochs=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred=model.predict(input_fn=pred_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Gnana\\AppData\\Local\\Temp\\tmptjt8qt6b\\model.ckpt-26000\n"
     ]
    }
   ],
   "source": [
    "predictions=list(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_values=[]\n",
    "for predict in predictions:\n",
    "    predict_values.append(predict['predictions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81271.742946973201"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,predict_values)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
