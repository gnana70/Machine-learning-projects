{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder for PCA - EXERCISE \n",
    "\n",
    "** Follow the bold instructions below to reduce a 30 dimensional data set for classification into a 2-dimensional dataset! Then use the color classes to see if you still kept the same level of class separation in the dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "** Import numpy, matplotlib, and pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use pandas to read in the csv file called anonymized_data.csv . It contains 500 rows and 30 columns of anonymized data along with 1 last column with a classification label, where the columns have been renamed to 4 letter codes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('anonymized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.032145</td>\n",
       "      <td>1.019576</td>\n",
       "      <td>-9.658715</td>\n",
       "      <td>-6.210495</td>\n",
       "      <td>3.156823</td>\n",
       "      <td>7.457850</td>\n",
       "      <td>-5.313357</td>\n",
       "      <td>8.508296</td>\n",
       "      <td>3.959194</td>\n",
       "      <td>-5.246654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.209663</td>\n",
       "      <td>-10.340123</td>\n",
       "      <td>-7.697555</td>\n",
       "      <td>-5.932752</td>\n",
       "      <td>10.872688</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>1.276316</td>\n",
       "      <td>5.281225</td>\n",
       "      <td>-0.516447</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.306217</td>\n",
       "      <td>6.649376</td>\n",
       "      <td>-0.960333</td>\n",
       "      <td>-4.094799</td>\n",
       "      <td>8.738965</td>\n",
       "      <td>-3.458797</td>\n",
       "      <td>7.016800</td>\n",
       "      <td>6.692765</td>\n",
       "      <td>0.898264</td>\n",
       "      <td>9.337643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851793</td>\n",
       "      <td>-9.678324</td>\n",
       "      <td>-6.071795</td>\n",
       "      <td>1.428194</td>\n",
       "      <td>-8.082792</td>\n",
       "      <td>-0.557089</td>\n",
       "      <td>-7.817282</td>\n",
       "      <td>-8.686722</td>\n",
       "      <td>-6.953100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.570842</td>\n",
       "      <td>6.985462</td>\n",
       "      <td>-1.842621</td>\n",
       "      <td>-1.569599</td>\n",
       "      <td>10.039339</td>\n",
       "      <td>-3.623026</td>\n",
       "      <td>8.957619</td>\n",
       "      <td>7.577283</td>\n",
       "      <td>1.541255</td>\n",
       "      <td>7.161509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376085</td>\n",
       "      <td>-8.971164</td>\n",
       "      <td>-5.302191</td>\n",
       "      <td>2.898965</td>\n",
       "      <td>-8.746597</td>\n",
       "      <td>-0.520888</td>\n",
       "      <td>-7.350999</td>\n",
       "      <td>-8.925501</td>\n",
       "      <td>-7.051179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.139972</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>-9.526530</td>\n",
       "      <td>-5.744928</td>\n",
       "      <td>4.834355</td>\n",
       "      <td>5.907235</td>\n",
       "      <td>-4.804137</td>\n",
       "      <td>6.798810</td>\n",
       "      <td>5.403670</td>\n",
       "      <td>-7.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270571</td>\n",
       "      <td>-8.640988</td>\n",
       "      <td>-8.105419</td>\n",
       "      <td>-5.079015</td>\n",
       "      <td>9.351282</td>\n",
       "      <td>0.641759</td>\n",
       "      <td>1.898083</td>\n",
       "      <td>3.904671</td>\n",
       "      <td>1.453499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.738104</td>\n",
       "      <td>0.234729</td>\n",
       "      <td>-11.558768</td>\n",
       "      <td>-7.181332</td>\n",
       "      <td>4.189626</td>\n",
       "      <td>7.765274</td>\n",
       "      <td>-2.189083</td>\n",
       "      <td>7.239925</td>\n",
       "      <td>3.135602</td>\n",
       "      <td>-6.211390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>-9.437110</td>\n",
       "      <td>-6.475267</td>\n",
       "      <td>-5.708377</td>\n",
       "      <td>9.623080</td>\n",
       "      <td>1.802899</td>\n",
       "      <td>1.903705</td>\n",
       "      <td>4.188442</td>\n",
       "      <td>1.522362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EJWY      VALM       EGXO      HTGR       SKRF      NNSZ      NYLC  \\\n",
       "0 -2.032145  1.019576  -9.658715 -6.210495   3.156823  7.457850 -5.313357   \n",
       "1  8.306217  6.649376  -0.960333 -4.094799   8.738965 -3.458797  7.016800   \n",
       "2  6.570842  6.985462  -1.842621 -1.569599  10.039339 -3.623026  8.957619   \n",
       "3 -1.139972  0.579422  -9.526530 -5.744928   4.834355  5.907235 -4.804137   \n",
       "4 -1.738104  0.234729 -11.558768 -7.181332   4.189626  7.765274 -2.189083   \n",
       "\n",
       "       GWID      TVUT      CJHI  ...        LKKS       UOBF      VBHE  \\\n",
       "0  8.508296  3.959194 -5.246654  ...   -2.209663 -10.340123 -7.697555   \n",
       "1  6.692765  0.898264  9.337643  ...    0.851793  -9.678324 -6.071795   \n",
       "2  7.577283  1.541255  7.161509  ...    1.376085  -8.971164 -5.302191   \n",
       "3  6.798810  5.403670 -7.642857  ...    0.270571  -8.640988 -8.105419   \n",
       "4  7.239925  3.135602 -6.211390  ...   -0.013973  -9.437110 -6.475267   \n",
       "\n",
       "       FRWU       NDYZ      QSBO      JDUB      TEVK      EZTM  Label  \n",
       "0 -5.932752  10.872688  0.081321  1.276316  5.281225 -0.516447    0.0  \n",
       "1  1.428194  -8.082792 -0.557089 -7.817282 -8.686722 -6.953100    1.0  \n",
       "2  2.898965  -8.746597 -0.520888 -7.350999 -8.925501 -7.051179    1.0  \n",
       "3 -5.079015   9.351282  0.641759  1.898083  3.904671  1.453499    0.0  \n",
       "4 -5.708377   9.623080  1.802899  1.903705  4.188442  1.522362    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 31 columns):\n",
      "EJWY     500 non-null float64\n",
      "VALM     500 non-null float64\n",
      "EGXO     500 non-null float64\n",
      "HTGR     500 non-null float64\n",
      "SKRF     500 non-null float64\n",
      "NNSZ     500 non-null float64\n",
      "NYLC     500 non-null float64\n",
      "GWID     500 non-null float64\n",
      "TVUT     500 non-null float64\n",
      "CJHI     500 non-null float64\n",
      "NVFW     500 non-null float64\n",
      "VLBG     500 non-null float64\n",
      "IDIX     500 non-null float64\n",
      "UVHN     500 non-null float64\n",
      "IWOT     500 non-null float64\n",
      "LEMB     500 non-null float64\n",
      "QMYY     500 non-null float64\n",
      "XDGR     500 non-null float64\n",
      "ODZS     500 non-null float64\n",
      "LNJS     500 non-null float64\n",
      "WDRT     500 non-null float64\n",
      "LKKS     500 non-null float64\n",
      "UOBF     500 non-null float64\n",
      "VBHE     500 non-null float64\n",
      "FRWU     500 non-null float64\n",
      "NDYZ     500 non-null float64\n",
      "QSBO     500 non-null float64\n",
      "JDUB     500 non-null float64\n",
      "TEVK     500 non-null float64\n",
      "EZTM     500 non-null float64\n",
      "Label    500 non-null float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 121.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "\n",
    "** Use scikit learn to scale the data with a MinMaxScaler. Remember not to scale the Label column, just the data. Save this scaled data as a new variable called scaled_data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=data.iloc[:,:-1].values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaled_data=scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Linear Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import tensorflow and import fully_connected layers from tensorflow.contrib.layers. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fill out the number of inputs to fit the dimensions of the data set and set the hidden number of units to be 2. Also set the number of outputs to match the number of inputs. Also choose a learning_rate value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs =30 # FILL ME IN\n",
    "num_hidden = 2 # FILL ME IN \n",
    "num_outputs = num_inputs # Must be true for an autoencoder!\n",
    "\n",
    "learning_rate =0.01 #FILL ME IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "\n",
    "** Create a placeholder fot the data called X.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,[None,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "** Create the hidden layer and the output layers using the fully_connected function. Remember that to perform PCA there is no activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer=fully_connected(X,num_outputs=2,activation_fn=None)\n",
    "output_layer=fully_connected(hidden_layer,num_outputs=30,activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "** Create a Mean Squared Error loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.square(output_layer-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create an AdamOptimizer designed to minimize the previous loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "model=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init\n",
    "\n",
    "** Create an instance of a global variable intializer. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session\n",
    "\n",
    "** Now create a Tensorflow session that runs the optimizer for at least 1000 steps. (You can also use epochs if you prefer, where 1 epoch is defined by one single run through the entire dataset. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    steps=1000\n",
    "    \n",
    "    for i in range(steps):\n",
    "        sess.run(model,feed_dict={X:scaled_data})\n",
    "    \n",
    "    output_2d = hidden_layer.eval(feed_dict={X: scaled_data})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a session that runs the scaled data through the hidden layer. (You could have also done this in the last step after all the training steps. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Confirm that your output is now 2 dimensional along the previous axis of 30 features. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2d.shape\n",
    "\n",
    "output_2d[:,0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now plot out the reduced dimensional representation of the data. Do you still have clear separation of classes even with the reduction in dimensions? Hint: You definitely should, the classes should still be clearly seperable, even when reduced to 2 dimensions. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x232a9060a20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQmo/wdRDgnbWgQvDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x232a8f2c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(output_2d[:,0],output_2d[:,1],c=data['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
